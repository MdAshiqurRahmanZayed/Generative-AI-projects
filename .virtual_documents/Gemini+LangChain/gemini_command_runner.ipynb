import os
import subprocess
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate





load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    raise EnvironmentError("GOOGLE_API_KEY not found in .env")






llm = ChatGoogleGenerativeAI(
    model="models/gemini-2.0-flash",
    google_api_key=GOOGLE_API_KEY
)





template = """
You are a helpful assistant that translates user input into shell commands (Linux/macOS).
Respond only with the shell command(s). Do not add explanations.

User request: {user_input}
Shell command:
"""


prompt = ChatPromptTemplate.from_template(template)





def get_shell_command(user_input: str) -> str:
    chain = prompt | llm
    print("\n🔍 Generating shell command from your request...")
    result = chain.invoke({"user_input": user_input})
    return result.content.strip()

def run_command_and_save_output(command: str, output_file: str = "output.txt"):
    print(f"\n🚀 Executing command: {command}\n")
    try:
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        output = result.stdout or result.stderr
        print("📄 Command Output:\n", output)
        with open(output_file, "w") as f:
            f.write(output)
        print(f"\n✅ Output saved to {output_file}")
    except Exception as e:
        print("❌ Error executing command:", e)





user_prompt = "My request is to list all files, including hidden files, in the current directory."


print("🔧 Gemini Command Runner (API Key Mode)")

shell_command = get_shell_command(user_prompt)
print(f"\n💡 Generated Command: {shell_command}")
confirm = input("\n❓Do you want to run this command? (y/n): ").strip().lower()

if confirm == "y":
    run_command_and_save_output(shell_command)
else:
    print("❎ Command execution canceled.")
